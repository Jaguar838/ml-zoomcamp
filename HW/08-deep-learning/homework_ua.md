## Домашнє завдання

> **Примітка**: дуже ймовірно, що у цьому завданні ваші відповіді не будуть повністю збігатися з запропонованими варіантами. Це нормально й очікувано. Оберіть варіант, який найближчий до вашого рішення.

### Набір даних

У цьому завданні ми створимо модель для класифікації різних типів волосся.  
Для цього ми будемо використовувати набір даних *Hair Type*, отриманий із  
[Kaggle](https://www.kaggle.com/datasets/kavyasreeb/hair-type-dataset)  
та трохи змінений.

Ви можете завантажити потрібний набір даних для цього завдання за посиланням:  
[тут](https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip):

```bash
wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip
unzip data.zip
```

На лекціях ми розглядали, як використовувати попередньо навчені нейронні мережі. У цьому завданні ми будемо навчати модель значно меншого розміру з нуля.

> **Примітка**: вам потрібне середовище з GPU для виконання цього завдання. Ми рекомендуємо використовувати [Saturn Cloud](https://bit.ly/saturn-mlzoomcamp).  
> Ви також можете використовувати комп’ютер без GPU (наприклад, ноутбук), але це буде повільніше.

### Підготовка даних

Набір даних містить близько 1000 зображень волосся у розділених папках  
для навчального та тестового наборів.

### Відтворюваність

Відтворюваність у глибокому навчанні є багатогранною задачею, яка потребує уваги  
до деталей програмного й апаратного забезпечення. У деяких випадках ми не можемо  
гарантувати абсолютно однакові результати під час повторних запусків експерименту.  
Тому в цьому завданні ми пропонуємо:
* встановити версію `tensorflow 2.17.1`
* встановити генератори випадкових чисел за допомогою:

```python
import numpy as np
import tensorflow as tf

SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)
```

### Модель

У цьому завданні ми будемо використовувати згорткову нейронну мережу (*CNN*).  
Як і на лекціях, ми використовуватимемо Keras.

Вам потрібно створити модель зі структурою:

* Вхідний шар повинен мати розмірність `(200, 200, 3)`
* Наступний шар — згортковий ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):
  * Використовуйте 32 фільтри
  * Розмір ядра повинен бути `(3, 3)` (розмір фільтра)
  * Використовуйте активацію `'relu'`
* Зменште розмір карти ознак за допомогою max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/)):
  * Встановіть розмір пулінгу `(2, 2)`
* Перетворіть багатовимірний результат у вектор за допомогою шару [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/)
* Додайте повнозв'язний (`Dense`) шар із 64 нейронами та активацією `'relu'`
* Створіть вихідний шар із 1 нейроном — це буде вихідний шар:
  * Для цього шару використовуйте відповідну активацію для задачі бінарної класифікації.

В якості оптимізатора використовуйте [`SGD`](https://keras.io/api/optimizers/sgd/) із такими параметрами:

* `SGD(learning_rate=0.002, momentum=0.8)`

Для уточнення щодо розміру ядра та max pooling перегляньте [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc).

### Питання 1

Оскільки ми маємо задачу бінарної класифікації, яка функція втрат є найкращою для нас?

* `mean squared error`
* `binary crossentropy`
* `categorical crossentropy`
* `cosine similarity`

> **Примітка**: оскільки ми задаємо активацію для вихідного шару, нам не потрібно встановлювати `from_logits=True`.

---

### Питання 2

Яка загальна кількість параметрів у моделі? Ви можете використати метод `summary` для цього.

* 896
* 11214912
* 15896912
* 20072512

---

### Генератори та навчання

Для наступних двох питань використовуйте наступний генератор даних для навчальних і тестових наборів:

```python
ImageDataGenerator(rescale=1./255)
```

* Нам не потрібно виконувати додаткову обробку зображень.
* Під час читання даних із папок train/test зверніть увагу на параметр `class_mode`. Яке значення має бути для задачі бінарної класифікації?
* Використовуйте `batch_size=20`.
* Використовуйте `shuffle=True` для навчального й тестового наборів.

Для навчання використовуйте метод `.fit()` із такими параметрами:

```python
model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator
)
```
---

### Питання 3

Яка медіана точності навчання (*training accuracy*) за всі епохи для цієї моделі?

* 0.10
* 0.32
* 0.50
* 0.72

---

### Питання 4

Яке стандартне відхилення втрат навчання (*training loss*) за всі епохи для цієї моделі?

* 0.028
* 0.068
* 0.128
* 0.168

---

### Розширення даних (*Data Augmentation*)

Для наступних двох питань ми згенеруємо більше даних за допомогою розширень.

Додайте наступні розширення до вашого генератора навчальних даних:

* `rotation_range=50,`
* `width_shift_range=0.1,`
* `height_shift_range=0.1,`
* `zoom_range=0.1,`
* `horizontal_flip=True,`
* `fill_mode='nearest'`

---

### Питання 5

Навчайте нашу модель ще протягом 10 епох, використовуючи той самий код, як і раніше.
> **Примітка**: переконайтеся, що ви не створюєте модель заново — ми хочемо продовжити навчання  
моделі, яку вже почали тренувати.

Яке середнє значення втрат на тестовому наборі (*test loss*) за всі епохи для моделі, навченої з розширеннями?

* 0.26
* 0.56
* 0.86
* 1.16

---

### Питання 6

Яке середнє значення точності на тестовому наборі (*test accuracy*) за останні 5 епох (з 6 по 10)  
для моделі, навченої з розширеннями?

* 0.31
* 0.51
* 0.71
* 0.91

---

## Надішліть результати

* Надішліть свої відповіді тут: https://courses.datatalks.club/ml-zoomcamp-2024/homework/hw08
* Якщо ваша відповідь не збігається з варіантами повністю, оберіть найближчий.