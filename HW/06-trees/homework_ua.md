## Домашнє завдання

> Примітка: інколи ваша відповідь не буде повністю збігатися з одним із варіантів. Це нормально. Оберіть варіант, який найбільше наближений до вашого рішення.

### Набір даних

Для цього домашнього завдання ми будемо використовувати набір даних про успішність студентів на екзамені JAMB 2024 з [Kaggle](https://www.kaggle.com/datasets/idowuadamo/students-performance-in-2024-jamb).

Ось [посилання](https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv), яке можна використати з `wget`:

```bash
wget https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv
```

Мета цього завдання - створити модель регресії для прогнозування успішності студентів на стандартизованому тесті (стовпець `'JAMB_Score'`).

### Підготовка набору даних

Спочатку зробимо імена стовпців малими літерами:

```python
df.columns = df.columns.str.lower().str.replace(' ', '_')
```

Підготовка:

* Видаліть стовпець `student_id`.
* Заповніть пропущені значення нулями.
* Розділіть дані на тренувальну, валідаційну та тестову вибірки у співвідношенні 60%/20%/20%.
* Використайте функцію `train_test_split` і встановіть параметр `random_state` на 1.
* Використайте `DictVectorizer(sparse=True)`, щоб перетворити датафрейми на матриці.

## Питання 1

Навчимо регресор на основі дерева рішень для прогнозування змінної `jamb_score`.

* Навчіть модель з `max_depth=1`.

Яка ознака використовується для поділу даних?

* `study_hours_per_week`
* `attendance_rate`
* `teacher_quality`
* `distance_to_school`

## Питання 2

Навчіть модель випадкового лісу з такими параметрами:

* `n_estimators=10`
* `random_state=1`
* `n_jobs=-1` (опціонально - для прискорення навчання)

Яке значення RMSE у цієї моделі на валідаційному наборі?

* 22.13
* 42.13
* 62.13
* 82.12

## Питання 3

Тепер давайте експериментувати з параметром `n_estimators`

* Спробуйте різні значення цього параметра від 10 до 200 з кроком 10.
* Встановіть `random_state` на 1.
* Оцініть модель на валідаційному наборі даних.

Після якого значення `n_estimators` RMSE перестає покращуватись?
Розрахуйте з точністю до 3-х знаків після коми.

* 10
* 25
* 80
* 200

## Питання 4

Давайте виберемо найкращий `max_depth`:

* Спробуйте різні значення `max_depth`: `[10, 15, 20, 25]`
* Для кожного з цих значень:
  * Спробуйте різні значення `n_estimators` від 10 до 200 (з кроком 10)
  * Розрахуйте середнє значення RMSE
* Встановіть випадковий генератор: `random_state=1`

Яке найкраще значення `max_depth`, використовуючи середнє значення RMSE?

* 10
* 15
* 20
* 25

## Питання 5

Ми можемо отримати інформацію про важливість ознак із моделей на основі дерев.

На кожному кроці алгоритм навчання дерева рішень знаходить найкращий поділ. 
При цьому ми можемо розрахувати "приріст" - зменшення "нечіткості" до і після поділу. 
Цей приріст є досить корисним для розуміння важливих ознак у моделях на основі дерев.

У Scikit-Learn моделі на основі дерев містять цю інформацію в
полі [`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_).

Для цього питання навчимо модель з такими параметрами:

* `n_estimators=10`
* `max_depth=20`
* `random_state=1`
* `n_jobs=-1` (опціонально)

Отримайте інформацію про важливість ознак з цієї моделі.

Яка найважливіша ознака (серед цих 4)?

* `study_hours_per_week`
* `attendance_rate`
* `distance_to_school`
* `teacher_quality`

## Питання 6

Тепер навчимо модель XGBoost! Для цього питання ми налаштуємо параметр `eta`:

* Встановіть XGBoost
* Створіть DMatrix для тренувальної та валідаційної вибірок
* Створіть watchlist
* Навчіть модель з такими параметрами протягом 100 раундів:

```
xgb_params = {
    'eta': 0.3, 
    'max_depth': 6,
    'min_child_weight': 1,
    
    'objective': 'reg:squarederror',
    'nthread': 8,
    
    'seed': 1,
    'verbosity': 1,
}
```

Тепер змініть `eta` з `0.3` на `0.1`.

Яке значення `eta` дає найкращий результат RMSE на валідаційному наборі?

* 0.3
* 0.1
* Обидва дають однакове значення

## Надішліть результати

* Надішліть свої результати тут: https://courses.datatalks.club/ml-zoomcamp-2024/homework/hw06
* Якщо ваша відповідь не повністю збігається з варіантами, оберіть найближчий варіант.